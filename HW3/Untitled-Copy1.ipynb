{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spam = pd.read_csv(\"C:/Users/mouni/Downloads/SML/HW3/spambase/spambase.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "data_scaled = scaler.fit_transform(data_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data_scaled[:,0:],\n",
    "                  index=data_scaled[:,0],\n",
    "                  columns=['word_freq_make', 'word_freq_address','word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
    " 'word_freq_over', 'word_freq_remove', 'word_freq_internet','word_freq_order', 'word_freq_mail',\n",
    " 'word_freq_receive','word_freq_will', 'word_freq_people', 'word_freq_report',\n",
    " 'word_freq_addresses', 'word_freq_free', 'word_freq_business','word_freq_email',\n",
    " 'word_freq_you', 'word_freq_credit', 'word_freq_your','word_freq_font', 'word_freq_000',\n",
    " 'word_freq_money', 'word_freq_hp','word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab',\n",
    " 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data','word_freq_415', 'word_freq_85',\n",
    " 'word_freq_technology', 'word_freq_1999','word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    " 'word_freq_cs','word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
    " 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_semicolon',\n",
    " 'char_freq_leftparen', 'char_freq_leftsquare', 'char_freq_bang', 'char_freq_dollar',\n",
    " 'char_freq_hash','capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'is_spam'])\n",
    "\n",
    "\n",
    "# ['word_freq_make', 'word_freq_address','word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
    "#  'word_freq_over', 'word_freq_remove', 'word_freq_internet','word_freq_order', 'word_freq_mail',\n",
    "#  'word_freq_receive','word_freq_will', 'word_freq_people', 'word_freq_report',\n",
    "#  'word_freq_addresses', 'word_freq_free', 'word_freq_business','word_freq_email',\n",
    "#  'word_freq_you', 'word_freq_credit', 'word_freq_your','word_freq_font', 'word_freq_000',\n",
    "#  'word_freq_money', 'word_freq_hp','word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab',\n",
    "#  'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data','word_freq_415', 'word_freq_85',\n",
    "#  'word_freq_technology', 'word_freq_1999','word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "#  'word_freq_cs','word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
    "#  'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_semicolon',\n",
    "#  'char_freq_leftparen', 'char_freq_leftsquare', 'char_freq_bang', 'char_freq_dollar',\n",
    "#  'char_freq_hash','capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_spam = data_spam.rename(columns={'0':'word_freq_make',\n",
    "                          '0.64':'word_freq_address',\n",
    "                          '0.64.1':'word_freq_all',\n",
    "                          '0.1':'word_freq_3d',\n",
    "                          '0.32':'word_freq_our',\n",
    "                          '0.2':'word_freq_over',\n",
    "                          '0.3':'word_freq_remove',\n",
    "                          '0.4':'word_freq_internet',\n",
    "                          '0.5':'word_freq_order',\n",
    "                          '0.6':'word_freq_mail',\n",
    "                          '0.7':'word_freq_receive',\n",
    "                          '0.64.2':'word_freq_will',\n",
    "                          '0.8':'word_freq_people',\n",
    "                          '0.9':'word_freq_report',\n",
    "                          '0.10':'word_freq_addresses',\n",
    "                          '0.32.1':'word_freq_free',\n",
    "                          '0.11':'word_freq_business',\n",
    "                          '1.29':'word_freq_email',\n",
    "                          '1.93':'word_freq_you',\n",
    "                          '0.12':'word_freq_credit',\n",
    "                          '0.96':'word_freq_your',\n",
    "                          '0.13':'word_freq_font',\n",
    "                          '0.14':'word_freq_000',\n",
    "                          '0.15':'word_freq_money',\n",
    "                          '0.16':'word_freq_hp',\n",
    "                          '0.17':'word_freq_hpl',\n",
    "                          '0.18':'word_freq_george',\n",
    "                          '0.19':'word_freq_650',\n",
    "                          '0.20':'word_freq_lab',\n",
    "                          '0.21':'word_freq_labs',\n",
    "                          '0.22':'word_freq_telnet',\n",
    "                          '0.23':'word_freq_857',\n",
    "                          '0.24':'word_freq_data',\n",
    "                          '0.25':'word_freq_415',\n",
    "                          '0.26':'word_freq_85',\n",
    "                          '0.27':'word_freq_technology',\n",
    "                          '0.28':'word_freq_1999',\n",
    "                          '0.29':'word_freq_parts',\n",
    "                          '0.30':'word_freq_pm',\n",
    "                          '0.31':'word_freq_direct',\n",
    "                          '0.32.2':'word_freq_cs',\n",
    "                          '0.33':'word_freq_meeting',\n",
    "                          '0.34':'word_freq_original',\n",
    "                          '0.35':'word_freq_project',\n",
    "                          '0.36':'word_freq_re',\n",
    "                          '0.37':'word_freq_edu',\n",
    "                          '0.38':'word_freq_table',\n",
    "                          '0.39':'word_freq_conference',\n",
    "                          '0.40':'char_freq_semicolon',\n",
    "                          '0.41':'char_freq_leftparen',\n",
    "                          '0.42':'char_freq_leftsquare',\n",
    "                          '0.778':'char_freq_bang',\n",
    "                          '0.43':'char_freq_dollar',\n",
    "                          '0.44':'char_freq_hash',\n",
    "                          '3.756':'capital_run_length_average',\n",
    "                          '61':'capital_run_length_longest',\n",
    "                          '278':'capital_run_length_total',\n",
    "                          '1':'is_spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(df, df.iloc[:,-1], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.drop(columns = ['is_spam'])\n",
    "xTest = xTest.drop(columns = ['is_spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600, 58)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_semicolon</th>\n",
       "      <th>char_freq_leftparen</th>\n",
       "      <th>char_freq_leftsquare</th>\n",
       "      <th>char_freq_bang</th>\n",
       "      <th>char_freq_dollar</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.345252</th>\n",
       "      <td>0.345252</td>\n",
       "      <td>0.051976</td>\n",
       "      <td>0.435261</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>-0.256087</td>\n",
       "      <td>0.672259</td>\n",
       "      <td>0.244655</td>\n",
       "      <td>-0.088058</td>\n",
       "      <td>-0.323341</td>\n",
       "      <td>1.086529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158471</td>\n",
       "      <td>-0.026117</td>\n",
       "      <td>-0.155215</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>0.423674</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>0.250546</td>\n",
       "      <td>1.228189</td>\n",
       "      <td>1.240416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.145982</th>\n",
       "      <td>-0.145982</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>0.851833</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>1.364700</td>\n",
       "      <td>0.343576</td>\n",
       "      <td>0.193562</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>1.973754</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117398</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>-0.155215</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>0.439942</td>\n",
       "      <td>-0.079768</td>\n",
       "      <td>0.145895</td>\n",
       "      <td>2.220875</td>\n",
       "      <td>3.258376</td>\n",
       "      <td>1.240416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.342475</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>-0.556576</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>0.472524</td>\n",
       "      <td>-0.350309</td>\n",
       "      <td>0.500124</td>\n",
       "      <td>1.308212</td>\n",
       "      <td>0.789315</td>\n",
       "      <td>0.605719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158471</td>\n",
       "      <td>-0.007622</td>\n",
       "      <td>-0.155215</td>\n",
       "      <td>-0.161788</td>\n",
       "      <td>-0.308392</td>\n",
       "      <td>-0.103060</td>\n",
       "      <td>-0.052154</td>\n",
       "      <td>-0.062450</td>\n",
       "      <td>-0.152207</td>\n",
       "      <td>1.240416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.342475</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>-0.556576</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>0.472524</td>\n",
       "      <td>-0.350309</td>\n",
       "      <td>0.500124</td>\n",
       "      <td>1.308212</td>\n",
       "      <td>0.789315</td>\n",
       "      <td>0.605719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158471</td>\n",
       "      <td>-0.015020</td>\n",
       "      <td>-0.155215</td>\n",
       "      <td>-0.164240</td>\n",
       "      <td>-0.308392</td>\n",
       "      <td>-0.103060</td>\n",
       "      <td>-0.052154</td>\n",
       "      <td>-0.062450</td>\n",
       "      <td>-0.152207</td>\n",
       "      <td>1.240416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.342475</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>-0.556576</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>2.286616</td>\n",
       "      <td>-0.350309</td>\n",
       "      <td>-0.291828</td>\n",
       "      <td>4.350087</td>\n",
       "      <td>-0.323341</td>\n",
       "      <td>-0.371410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158471</td>\n",
       "      <td>0.310487</td>\n",
       "      <td>-0.155215</td>\n",
       "      <td>-0.329755</td>\n",
       "      <td>-0.308392</td>\n",
       "      <td>-0.103060</td>\n",
       "      <td>-0.069079</td>\n",
       "      <td>-0.190726</td>\n",
       "      <td>-0.378150</td>\n",
       "      <td>1.240416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       " 0.345252        0.345252           0.051976       0.435261     -0.046905   \n",
       "-0.145982       -0.145982          -0.164984       0.851833     -0.046905   \n",
       "-0.342475       -0.342475          -0.164984      -0.556576     -0.046905   \n",
       "-0.342475       -0.342475          -0.164984      -0.556576     -0.046905   \n",
       "-0.342475       -0.342475          -0.164984      -0.556576     -0.046905   \n",
       "\n",
       "           word_freq_our  word_freq_over  word_freq_remove  \\\n",
       " 0.345252      -0.256087        0.672259          0.244655   \n",
       "-0.145982       1.364700        0.343576          0.193562   \n",
       "-0.342475       0.472524       -0.350309          0.500124   \n",
       "-0.342475       0.472524       -0.350309          0.500124   \n",
       "-0.342475       2.286616       -0.350309         -0.291828   \n",
       "\n",
       "           word_freq_internet  word_freq_order  word_freq_mail  ...  \\\n",
       " 0.345252           -0.088058        -0.323341        1.086529  ...   \n",
       "-0.145982            0.036609         1.973754        0.016339  ...   \n",
       "-0.342475            1.308212         0.789315        0.605719  ...   \n",
       "-0.342475            1.308212         0.789315        0.605719  ...   \n",
       "-0.342475            4.350087        -0.323341       -0.371410  ...   \n",
       "\n",
       "           char_freq_semicolon  char_freq_leftparen  char_freq_leftsquare  \\\n",
       " 0.345252            -0.158471            -0.026117             -0.155215   \n",
       "-0.145982            -0.117398             0.014571             -0.155215   \n",
       "-0.342475            -0.158471            -0.007622             -0.155215   \n",
       "-0.342475            -0.158471            -0.015020             -0.155215   \n",
       "-0.342475            -0.158471             0.310487             -0.155215   \n",
       "\n",
       "           char_freq_bang  char_freq_dollar  char_freq_hash  \\\n",
       " 0.345252        0.126330          0.423674        0.008739   \n",
       "-0.145982        0.008631          0.439942       -0.079768   \n",
       "-0.342475       -0.161788         -0.308392       -0.103060   \n",
       "-0.342475       -0.164240         -0.308392       -0.103060   \n",
       "-0.342475       -0.329755         -0.308392       -0.103060   \n",
       "\n",
       "           capital_run_length_average  capital_run_length_longest  \\\n",
       " 0.345252                   -0.002453                    0.250546   \n",
       "-0.145982                    0.145895                    2.220875   \n",
       "-0.342475                   -0.052154                   -0.062450   \n",
       "-0.342475                   -0.052154                   -0.062450   \n",
       "-0.342475                   -0.069079                   -0.190726   \n",
       "\n",
       "           capital_run_length_total   is_spam  \n",
       " 0.345252                  1.228189  1.240416  \n",
       "-0.145982                  3.258376  1.240416  \n",
       "-0.342475                 -0.152207  1.240416  \n",
       "-0.342475                 -0.152207  1.240416  \n",
       "-0.342475                 -0.378150  1.240416  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mouni\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "fit1 = logisticRegr.fit(xTrain, yTrain)\n",
    "fit1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[659  33]\n",
      " [ 39 419]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, predictions)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9373913043478261\n"
     ]
    }
   ],
   "source": [
    "score = logisticRegr.score(xTest, yTest)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       692\n",
      "           1       0.93      0.91      0.92       458\n",
      "\n",
      "    accuracy                           0.94      1150\n",
      "   macro avg       0.94      0.93      0.93      1150\n",
      "weighted avg       0.94      0.94      0.94      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(yTest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9373913043478261\n",
      "Recall: 0.9148471615720524\n",
      "Precision: 0.9269911504424779\n",
      "Error: 0.06260869565217386\n",
      "F1 score: 0.9208791208791209\n"
     ]
    }
   ],
   "source": [
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Accuracy:\", ACC)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Recall:\", TPR)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Precision:\", PPV)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.89705119e-01, -1.74935550e-01,  1.71570781e-01,\n",
       "         8.95280705e-01,  5.15046824e-01,  8.16289595e-01,\n",
       "         2.08980476e+00,  5.39606591e-01,  6.26567932e-01,\n",
       "         5.81491034e-02, -4.78114083e-01, -1.97107263e-01,\n",
       "         2.04675029e-01,  6.95789812e-02,  1.13322547e+00,\n",
       "         1.18778391e+00,  8.71963206e-01,  1.31239460e-01,\n",
       "         8.78347403e-02,  8.82517127e-01,  1.86309085e-01,\n",
       "         1.14773478e-01,  1.93366508e+00,  3.14887478e-01,\n",
       "        -1.58094140e+00, -9.37479661e-01, -3.22726694e+00,\n",
       "         4.11610783e-01, -1.29779737e+00, -1.50744047e-01,\n",
       "        -1.85373154e+00,  1.15866574e-01, -8.71732847e-01,\n",
       "         2.01353476e-01, -1.51435200e+00,  7.76156125e-01,\n",
       "        -2.85505738e-02,  1.45338841e-01, -7.30478283e-01,\n",
       "        -7.29581313e-01, -1.47706489e+00, -1.83036465e+00,\n",
       "        -6.15666584e-01, -1.21494604e+00, -7.28492138e-01,\n",
       "        -1.53169016e+00, -6.83330306e-01, -1.58345273e+00,\n",
       "        -1.00316044e+00, -4.25317998e-02, -6.69305936e-01,\n",
       "         2.51117970e-01,  3.05381667e+00,  1.07417755e+00,\n",
       "         2.15688939e-01,  4.88389382e-03,  5.26916686e-04]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 33 659]\n",
      " [419  39]]\n"
     ]
    }
   ],
   "source": [
    "prediction_T = logisticRegr.predict_proba(xTest)>= 0.5\n",
    "\n",
    "prediction_T = prediction_T[:,0]\n",
    "cm = metrics.confusion_matrix(yTest, prediction_T)\n",
    "print(cm)\n",
    "TN = cm[1][0]\n",
    "FN = cm[0][0]\n",
    "FP = cm[1][1]\n",
    "TP = cm[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9373913043478261\n",
      "Recall: 0.9523121387283237\n",
      "Precision: 0.9441260744985673\n",
      "Error: 0.06260869565217386\n",
      "F1 score: 0.9482014388489208\n"
     ]
    }
   ],
   "source": [
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Accuracy:\", ACC)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Recall:\", TPR)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Precision:\", PPV)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14 678]\n",
      " [363  95]]\n"
     ]
    }
   ],
   "source": [
    "prediction_T = logisticRegr.predict_proba(xTest)>= 0.25\n",
    "\n",
    "prediction_T = prediction_T[:,0]\n",
    "cm = metrics.confusion_matrix(yTest, prediction_T)\n",
    "print(cm)\n",
    "TN = cm[1][0]\n",
    "FN = cm[0][0]\n",
    "FP = cm[1][1]\n",
    "TP = cm[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9052173913043479\n",
      "Recall: 0.9797687861271677\n",
      "Precision: 0.8771021992238034\n",
      "Error: 0.09478260869565214\n",
      "F1 score: 0.9255972696245733\n"
     ]
    }
   ],
   "source": [
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Accuracy:\", ACC)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Recall:\", TPR)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Precision:\", PPV)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105 587]\n",
      " [447  11]]\n"
     ]
    }
   ],
   "source": [
    "prediction_T = logisticRegr.predict_proba(xTest)>= 0.75\n",
    "\n",
    "prediction_T = prediction_T[:,0]\n",
    "cm = metrics.confusion_matrix(yTest, prediction_T)\n",
    "print(cm)\n",
    "TN = cm[1][0]\n",
    "FN = cm[0][0]\n",
    "FP = cm[1][1]\n",
    "TP = cm[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8991304347826087\n",
      "Recall: 0.8482658959537572\n",
      "Precision: 0.9816053511705686\n",
      "Error: 0.10086956521739132\n",
      "F1 score: 0.910077519379845\n"
     ]
    }
   ],
   "source": [
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Accuracy:\", ACC)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Recall:\", TPR)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Precision:\", PPV)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216 476]\n",
      " [455   3]]\n"
     ]
    }
   ],
   "source": [
    "prediction_T = logisticRegr.predict_proba(xTest)>= 0.9\n",
    "\n",
    "prediction_T = prediction_T[:,0]\n",
    "cm = metrics.confusion_matrix(yTest, prediction_T)\n",
    "print(cm)\n",
    "TN = cm[1][0]\n",
    "FN = cm[0][0]\n",
    "FP = cm[1][1]\n",
    "TP = cm[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8095652173913044\n",
      "Recall: 0.6878612716763006\n",
      "Precision: 0.9937369519832986\n",
      "Error: 0.19043478260869562\n",
      "F1 score: 0.8129803586678054\n"
     ]
    }
   ],
   "source": [
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"Accuracy:\", ACC)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"Recall:\", TPR)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"Precision:\", PPV)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
