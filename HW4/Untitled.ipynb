{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spam = pd.read_csv(\"C:/Users/mouni/Downloads/SML/HW4/spambase.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spam = data_spam.rename(columns={'0':'word_freq_make','0.64':'word_freq_address',\n",
    "                                      '0.64.1':'word_freq_all','0.1':'word_freq_3d',\n",
    "                                      '0.32':'word_freq_our','0.2':'word_freq_over',\n",
    "                                      '0.3':'word_freq_remove','0.4':'word_freq_internet',\n",
    "                                      '0.5':'word_freq_order','0.6':'word_freq_mail',\n",
    "                                      '0.7':'word_freq_receive','0.64.2':'word_freq_will','0.8':'word_freq_people',\n",
    "                                      '0.9':'word_freq_report','0.10':'word_freq_addresses','0.32.1':'word_freq_free',\n",
    "                                      '0.11':'word_freq_business','1.29':'word_freq_email',\n",
    "                                      '1.93':'word_freq_you','0.12':'word_freq_credit','0.96':'word_freq_your',\n",
    "                                      '0.13':'word_freq_font','0.14':'word_freq_000','0.15':'word_freq_money',\n",
    "                                      '0.16':'word_freq_hp','0.17':'word_freq_hpl','0.18':'word_freq_george',\n",
    "                                      '0.19':'word_freq_650','0.20':'word_freq_lab','0.21':'word_freq_labs',\n",
    "                                      '0.22':'word_freq_telnet','0.23':'word_freq_857','0.24':'word_freq_data',\n",
    "                                      '0.25':'word_freq_415','0.26':'word_freq_85','0.27':'word_freq_technology',\n",
    "                                      '0.28':'word_freq_1999','0.29':'word_freq_parts','0.30':'word_freq_pm',\n",
    "                                      '0.31':'word_freq_direct','0.32.2':'word_freq_cs','0.33':'word_freq_meeting',\n",
    "                                      '0.34':'word_freq_original','0.35':'word_freq_project','0.36':'word_freq_re',\n",
    "                                      '0.37':'word_freq_edu','0.38':'word_freq_table','0.39':'word_freq_conference',\n",
    "                                      '0.40':'char_freq_semicolon','0.41':'char_freq_leftparen',\n",
    "                                      '0.42':'char_freq_leftsquare','0.778':'char_freq_bang',\n",
    "                                      '0.43':'char_freq_dollar','0.44':'char_freq_hash',\n",
    "                                      '3.756':'capital_run_length_average','61':'capital_run_length_longest',\n",
    "                                      '278':'capital_run_length_total','1':'is_spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600, 57)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y = data_spam['is_spam']\n",
    "data_x = data_spam.drop(columns = ['is_spam'])\n",
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600, 57)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler() \n",
    "data_scaled = scaler.fit_transform(data_x)\n",
    "data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data_scaled[:,0:],\n",
    "                  index=data_scaled[:,0],\n",
    "                  columns=['word_freq_make', 'word_freq_address','word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
    "                           'word_freq_over', 'word_freq_remove', 'word_freq_internet','word_freq_order', 'word_freq_mail',\n",
    "                           'word_freq_receive','word_freq_will', 'word_freq_people', 'word_freq_report',\n",
    "                           'word_freq_addresses', 'word_freq_free', 'word_freq_business','word_freq_email',\n",
    "                           'word_freq_you', 'word_freq_credit', 'word_freq_your','word_freq_font', 'word_freq_000',\n",
    "                           'word_freq_money', 'word_freq_hp','word_freq_hpl', 'word_freq_george', 'word_freq_650',\n",
    "                           'word_freq_lab','word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data',\n",
    "                           'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999','word_freq_parts',\n",
    "                           'word_freq_pm', 'word_freq_direct', 'word_freq_cs','word_freq_meeting', 'word_freq_original',\n",
    "                           'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table',\n",
    "                           'word_freq_conference', 'char_freq_semicolon', 'char_freq_leftparen', 'char_freq_leftsquare',\n",
    "                           'char_freq_bang', 'char_freq_dollar', 'char_freq_hash','capital_run_length_average',\n",
    "                           'capital_run_length_longest', 'capital_run_length_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 [Ensemble classifiers]\n",
    "\n",
    "**Use the SPAMBASE dataset for this problem. Split the original data into 75% for training and 25% for\n",
    "testing (chosen at random).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(df, data_y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Use an existing package to train an AdaBoost algorithm with 10, 50, and 100 base classifiers. Use a\n",
    "decision tree as the base classification model. Report accuracy, error, precision, and recall on both the\n",
    "training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaboost_model1 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                    n_estimators=10)\n",
    "fit1 = Adaboost_model1.fit(xTrain,yTrain)\n",
    "AdaBoost_pred1 = Adaboost_model1.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost with base classifier 10:  0.9269565217391305\n",
      "Error: 0.07304347826086954\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       692\n",
      "           1       0.93      0.88      0.91       458\n",
      "\n",
      "    accuracy                           0.93      1150\n",
      "   macro avg       0.93      0.92      0.92      1150\n",
      "weighted avg       0.93      0.93      0.93      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Acc = metrics.accuracy_score(yTest, AdaBoost_pred1)\n",
    "print(\"Accuracy for AdaBoost with base classifier 10: \",Acc)\n",
    "print(\"Error:\", 1-Acc)\n",
    "print(\"\\n\",metrics.classification_report(yTest, AdaBoost_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661  31]\n",
      " [ 53 405]]\n",
      "\n",
      "Accuracy: 0.9269565217391305\n",
      "Recall: 0.8842794759825328\n",
      "Precision: 0.9288990825688074\n",
      "Error: 0.07304347826086954\n",
      "F1 score: 0.906040268456376\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, AdaBoost_pred1)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"\\nAccuracy:\", ACC)\n",
    "\n",
    "# Recall\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Precision \n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaboost_model2 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                    n_estimators=50)\n",
    "fit2 = Adaboost_model2.fit(xTrain,yTrain)\n",
    "AdaBoost_pred2 = Adaboost_model2.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost with base classifier 50:  0.9452173913043478\n",
      "Error: 0.05478260869565221\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       692\n",
      "           1       0.93      0.93      0.93       458\n",
      "\n",
      "    accuracy                           0.95      1150\n",
      "   macro avg       0.94      0.94      0.94      1150\n",
      "weighted avg       0.95      0.95      0.95      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Acc2 = metrics.accuracy_score(yTest, AdaBoost_pred2)\n",
    "print(\"Accuracy for AdaBoost with base classifier 50: \",Acc2)\n",
    "print(\"Error:\", 1-Acc2)\n",
    "print(\"\\n\",metrics.classification_report(yTest, AdaBoost_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661  31]\n",
      " [ 32 426]]\n",
      "\n",
      "Accuracy: 0.9452173913043478\n",
      "Recall: 0.9301310043668122\n",
      "Precision: 0.9321663019693655\n",
      "Error: 0.05478260869565221\n",
      "F1 score: 0.9311475409836065\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, AdaBoost_pred2)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"\\nAccuracy:\", ACC)\n",
    "\n",
    "# Recall\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Precision \n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaboost_model3 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                    n_estimators=100)\n",
    "fit3 = Adaboost_model3.fit(xTrain,yTrain)\n",
    "AdaBoost_pred3 = Adaboost_model3.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost with base classifier 100:  0.9495652173913044\n",
      "Error: 0.050434782608695605\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       692\n",
      "           1       0.93      0.94      0.94       458\n",
      "\n",
      "    accuracy                           0.95      1150\n",
      "   macro avg       0.95      0.95      0.95      1150\n",
      "weighted avg       0.95      0.95      0.95      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Acc3 = metrics.accuracy_score(yTest, AdaBoost_pred3)\n",
    "print(\"Accuracy for AdaBoost with base classifier 100: \",Acc3)\n",
    "print(\"Error:\", 1-Acc3)\n",
    "print(\"\\n\",metrics.classification_report(yTest, AdaBoost_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[661  31]\n",
      " [ 27 431]]\n",
      "\n",
      "Accuracy: 0.9495652173913044\n",
      "Recall: 0.9410480349344978\n",
      "Precision: 0.9329004329004329\n",
      "Error: 0.050434782608695605\n",
      "F1 score: 0.9369565217391305\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, AdaBoost_pred3)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"\\nAccuracy:\", ACC)\n",
    "\n",
    "# Recall\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Precision \n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Use an existing package to train a Random Forest algorithm with 10, 50, and 100 decision trees.\n",
    "Report similar metrics on both the training and testing sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_model1 = RandomForestClassifier(n_estimators=10)\n",
    "fit_rand1 = Rand_model1.fit(xTrain,yTrain)\n",
    "Rand_pred1 = Rand_model1.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost with base classifier 10:  0.9521739130434783\n",
      "Error: 0.047826086956521685\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       692\n",
      "           1       0.96      0.92      0.94       458\n",
      "\n",
      "    accuracy                           0.95      1150\n",
      "   macro avg       0.95      0.95      0.95      1150\n",
      "weighted avg       0.95      0.95      0.95      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Acc = metrics.accuracy_score(yTest, Rand_pred1)\n",
    "print(\"Accuracy for AdaBoost with base classifier 10: \",Acc)\n",
    "print(\"Error:\", 1-Acc)\n",
    "print(\"\\n\",metrics.classification_report(yTest, Rand_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[673  19]\n",
      " [ 36 422]]\n",
      "\n",
      "Accuracy: 0.9521739130434783\n",
      "Recall: 0.9213973799126638\n",
      "Precision: 0.9569160997732427\n",
      "Error: 0.047826086956521685\n",
      "F1 score: 0.9388209121245829\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, Rand_pred1)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"\\nAccuracy:\", ACC)\n",
    "\n",
    "# Recall\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Precision \n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_model2 = RandomForestClassifier(n_estimators=50)\n",
    "fit_rand2 = Rand_model2.fit(xTrain,yTrain)\n",
    "Rand_pred2 = Rand_model2.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost with base classifier 50:  0.957391304347826\n",
      "Error: 0.042608695652173956\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       692\n",
      "           1       0.96      0.93      0.95       458\n",
      "\n",
      "    accuracy                           0.96      1150\n",
      "   macro avg       0.96      0.95      0.96      1150\n",
      "weighted avg       0.96      0.96      0.96      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Acc1 = metrics.accuracy_score(yTest, Rand_pred2)\n",
    "print(\"Accuracy for AdaBoost with base classifier 50: \",Acc1)\n",
    "print(\"Error:\", 1-Acc1)\n",
    "print(\"\\n\",metrics.classification_report(yTest, Rand_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[676  16]\n",
      " [ 33 425]]\n",
      "\n",
      "Accuracy: 0.957391304347826\n",
      "Recall: 0.9279475982532751\n",
      "Precision: 0.963718820861678\n",
      "Error: 0.042608695652173956\n",
      "F1 score: 0.9454949944382647\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, Rand_pred2)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"\\nAccuracy:\", ACC)\n",
    "\n",
    "# Recall\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Precision \n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rand_model3 = RandomForestClassifier(n_estimators=100)\n",
    "fit_rand3 = Rand_model3.fit(xTrain,yTrain)\n",
    "Rand_pred3 = Rand_model3.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for AdaBoost with base classifier 100:  0.9521739130434783\n",
      "Error: 0.047826086956521685\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       692\n",
      "           1       0.95      0.93      0.94       458\n",
      "\n",
      "    accuracy                           0.95      1150\n",
      "   macro avg       0.95      0.95      0.95      1150\n",
      "weighted avg       0.95      0.95      0.95      1150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Acc2 = metrics.accuracy_score(yTest, Rand_pred3)\n",
    "print(\"Accuracy for AdaBoost with base classifier 100: \",Acc2)\n",
    "print(\"Error:\", 1-Acc2)\n",
    "print(\"\\n\",metrics.classification_report(yTest, Rand_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[669  23]\n",
      " [ 32 426]]\n",
      "\n",
      "Accuracy: 0.9521739130434783\n",
      "Recall: 0.9301310043668122\n",
      "Precision: 0.9487750556792873\n",
      "Error: 0.047826086956521685\n",
      "F1 score: 0.9393605292171996\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(yTest, Rand_pred3)\n",
    "print(cm)\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "TP = cm[1][1]\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"\\nAccuracy:\", ACC)\n",
    "\n",
    "# Recall\n",
    "recall = TP/(TP+FN)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Precision \n",
    "precision = TP/(TP+FP)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Error\n",
    "print(\"Error:\", 1-ACC)\n",
    "\n",
    "# F1 Score\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Compare AdaBoost with Random Forest for 10, 50, and 100 base learners based on these results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 [AdaBoost classifier] \n",
    "**In this exercise, you will implement the AdaBoost algorithm using decision stumps as weak learners.**\n",
    "\n",
    "**(a) Implement a decision stump classifier that splits on a single feature. You may use any method for\n",
    "finding the splitting feature and threshold as long as the decision stub performs better than random.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
